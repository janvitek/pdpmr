---
title: "Parallel Data Processing in MapReduce F'17"
---


## learning objectives

Big data is a catchall term for datasets that are resource intensive. This course will introduce student to parallel and distributed processing technologies for analyzing 'big data'.  The course will cover programming paradigms and abstractions for data analysis at scale. Students will gain an understanding of the performance and usability trade-offs of various technologies and paradigms. Students will become familiar with technologies such as Hadoop, Spark, H20 and TensorFlow amongst other. Hands-on assignments will focus on machine learning and data analysis tasks.  The class builds on known principles such as the design recipe, testing and code reviews.

## pre-requites

Students should have taken the Algorithms course, should enjoy programming and strive to write beautiful code.

## course staff

__Instructors:__ Jan Vitek and Konrad Siek
__Teaching Assistant:__ Aviral Goel

## workload

Approximatively fifteen hours a week, with regular codewalks and in-class tests.

## grading

The class grade is on 100 points with 20 points for in-class participation (quizzes, questions, paper presentation, note taking), 40 points for the final project (software, report and oral defense) and 40 points for codewalks. The final grade is given on a scale of A=90, A-=85, B+=80, B=75, B-=70, C=65, D=55.  Codewalks conducted in class focus on the student's code output and graded based on code quality.

## authorship policy

Every code element (file or function) __must__ have a note ascribing authorship to an initial author and, possibly,  multiple maintainers. Sharing code is allowed. Changing authorship is cheating. 

## academic integrity

Cheating means an F to all involved parties, expulsion from the class and notification of ORAF.

## class time

There will be few traditional lectures, instead we discuss code, books and papers. Student will answer questions about assigned reading during class. Students should notify the instructor of absences. A scribe will record discussions in a shared document.

## office hours

Daily 10am -- 11am.

## class hours

Forsyth Building, room 129, Tuesday, Friday 3:30 -- 5:00.

## grade challenges

All regrade requests and grade challenges __must__ be submitted in writing, private posts on Piazza, no more than __7 days__ after the grade was awarded.  


## code review and code walks

A code review is conducted after each task. Teams review other teams' work, commenting on code quality, design, documentation and tests. The goal is to produce actionable suggestions for improvements. The output of a review is a report. Code walks are in-class discussions of programming tasks that start from a code review and explore the implementation of a student's project. Review are emailed in PDF to the instructor and code authors. They comment on the report, code and packaging. The report should give sufficient information to understand what was achieved. It should be clear and complete. The code should be well documents, avoid repetition, have no obvious bugs, have authorship comments. The packaging should make the results easily reproducible.  Be curious about the code. Question the results. Don't waste space in your report on what works well -- spend your time on what could be improved. Avoid generalities, be precise, give examples.



## schedule

```{r,echo=FALSE,message=FALSE}
require(dplyr)
read.csv("schedule.csv") %>% select(-c(1,3)) -> data
knitr::kable(data, format = "markdown")
```

## reading

|     |   | |
|:----|:-----------------------------------------------|:-------------------|
|HTDG | _Hadoop The Definitive Guide_ 4th Edition,  White, __O'Reilly__ | (PDFs are googlable, perhaps here) |
|KKWZ | _Learning Spark_, __O’Reilly__                                  | |
|MR04 | _MapReduce: Simplified Data Processing on Large Clusters_,  Dean, Ghemawat, __OSDI04__ | PDF |
|FJ10 | _FlumeJava: Easy, Efficient Data-Parallel Pipelines_,  Chambers+, __PLDI'10__ | PDF |
|SK12 | _Possible Hadoop Trajectories Stonebraker_,   Kepner, __CACM'12__         | Text |
|S14  | _Hadoop at a Crossroads?_         Stonebraker, __CACM'14__                | Text |
|M3R12| _Increased Performance for In-Memory Hadoop Jobs_, Shinnar+, __VLDB'12__  | PDF|
|Z+12 | _A Fault-Tolerant Abstraction for In-Memory Cluster Comp_,  Zaharia+, __NSDI'12__ | PDF|
|J+12 | _The Performance of MapReduce: An In-depth Study_,  Jiang+, __VLDB'10__   |PDF |
|MAS11| _Evaluating MapReduce Performance Using Workload Suites_, Chen+, __MASCOTS'11__ |PDF|
|OS06 | _Bigtable: A Distributed Storage System for Structured Data_,  Chang+, __OSDI06__ | PDF|
|R+12 | _Nobody ever got fired for using Hadoop on a cluster_,  Rowstron+        | PDF |
|A+15 | _Spark SQL: Relational Data Processing in Spark_,   Armburst+, __SIGMOD15__ |PDF|
|O+14 | _Processing Theta-Joins using MapReduce_,        Okcan+ __SIGMOD11__        | PDF |
|AD15 | _Scaling spark in the real world: performance and usability_, Armburst+, __VLDB15__ |PDF|
|JMM  | _The Java Memory Model FAQ_  |link|

assignments

X0 Conconrdance
Time: 1 week
Prerequisites: Threads
Description:
A concordance is a tool lexicographers use to make dictionaries. It is a document that shows the list of words used in a specific body of work (corpus) and their immediate context. A context can be defined variously, but for our purposes it is 10 words appearing before and after the given word. For instance, here is the immediate context for an appearance of the word “fallow” in Shakespeare’s Henry V:
… prisoners wildly overgrown with hair, Put forth disorder'd twigs; her fallow 
    leas The darnel, hemlock and rank fumitory Doth root upon …

Task 1 (warm-up): Write a concordancer that accepts a text file and creates a concordance for all words appearing in the text file. Task 2: use threads (and appropriate synchronization) to parallelize parts of the creation of the concordance (while maintaining correctness).

Fine print:
(0) Individual assignment. TODO
A0 Inhale
Time: 1 week
Prerequisites: None
Description:
The Bureau of Transport Statistics' On-time Performance (OTP) dataset has information about flights in the USA. The full dataset covers 27 years of air travel and is over 60GB in plain text. For this assignment you should answer the question: Which airlines have the least expensive fares?
Fine print:
(0) Individual assignment. (1) Data for one  month is here. (2) Write a sequential Java program reading one gzipped file and writing results on the console. (3) The only output should be the K and F, one per line, where K is the number of corrupt lines of input (lines not in the same format as the rest and lines with flights that do not pass the sanity test),  F is  the number of sane flights. Next, output pairs "C p" where C is a carrier two letter code  and p is the mean price of tickets. Sort the list by increasing price.  (4) The sanity test is:
CRSArrTime and CRSDepTime should not be zero
timeZone = CRSArrTime - CRSDepTime - CRSElapsedTime;
timeZone % 60 should be 0
AirportID,  AirportSeqID, CityMarketID, StateFips, Wac should be larger than 0
Origin, Destination,  CityName, State, StateName should not be empty
For flights that not Cancelled:
ArrTime -  DepTime - ActualElapsedTime - timeZone should be zero
if ArrDelay > 0 then ArrDelay should equal to ArrDelayMinutes
if ArrDelay < 0 then ArrDelayMinutes should be zero
if ArrDelayMinutes >= 15 then ArrDel15 should be true
(5) Design the code with care as you will reuse it. Document and test it.  (6) The reference solution is ~1KLOC and prints 4083 for K, 435940 for F and, for instance, "UA 545.62".   Processing time is ~5 seconds. (7) Submit your assignment in tar file  Monisha Singh, <msingh28@ccs.neu.edu>. The title of the mail must be "6240-V A0" followed by your name.

A1 Threading
Time: 1 week
Prerequisites: A0, Parallelism and consistency
Description:
Airfares evolve with time, one month of traffic is not sufficient to answer which airline is the cheapest. Try with two years worth of OTP data. Improve throughput of your code with parallel processing primitives.

Fine print:
(0) Individual assignment. (1) The input is "-p -input=DIR" where DIR is the path to a directory containing data files. All files in the directory will be processed. (2) The output is K and F, and a sequence of "C p m"s where m is the median ticket price. Restrict your output to airlines that are active in January 2015. (3) Clean up your code, document and test it. (4) Sample data is here. (5) Values for K and F are 128160 and 12601051. One sample airline is "AS 202.36 171.57". The reference solution is 150LOC additional/changed over A0. Processing time is under a minute.(6) Submit your assignment as a single tar.gz file which unpacks into a directory named "LastName_FirstName_A1".  That directory should contain a README file that explains how to build and run your assignment.

A2 Distribution
Time: 1 week
Prerequisites: A1, Distributed programming
Description:
As data sizes increase the single machine version does not scale, use Map Reduce to solve A1.
Fine print:
(0) Group assignment, two students. (1) Provide code that can run in pseudo-distributed mode as well as on EMR. (3) Produce a graph that plots the average ticket price for each month for each airline.  Use R. No other output is required. (3) Include a script that executes everything and produces the graph. For example, if you use the Unix make command, you should have two targets pseudo and cloud such that typing make pseudo will create a HDFS file system, start hadoop, run your job, get the output, and produce the graph. Typing  make pseudo will run your code on EMR. (4) Only plot airlines with flights in 2015, limit yourself to the 10 airlines with the most flights overall. (5) Information on how to setup AWS is here. (6) Write a one page report that documents your implementation and that describes your results. The report should be automatically constructed as part of running the project to include the plot. (Hint: use LaTeX or Markdown) (7) Submit a tar.gz file which unpacks into a directory name "LastName1_LastName2_A2". That directory should contain a README file that explains how to build and run your code. Make sure that the code is portable. Document what it requires. (8) The reference solution builds off A1, adding 154 lines of Java code and 15 lines of R code.

A3 Redux
Time: 1 week
Prerequisites: Threads, Distributed programming
Description:
Compare the cost of computing (A) mean, (B) median, and (C) fast median for (i) single threaded and (ii) multi-threaded Java, as well as (iii) pseudo-distributed MR and (iv) distributed MR.
Fine print:
(0) Group assignment, two students. (1) Reuse previous implementations as much as possible. Output "m C v" triples where m identifies the month, C is an airline, and v is the median or mean. (2) Devise your own approach to speed up computation of the median, this may include approximation techniques. If you choose to approximate, make sure to measure accuracy.  (3) Evaluate the performance of the following configurations i-A, i-B, ii-A, ii-B, iii-A, iii-B, iii-C, iv-A, iv-B, iv-C. (4) Create a benchmarking harness that will automatically run all configurations for different input sizes and generate graphs of the performance. The harness should output timings in a CSV file and generate a  PDF using R. (5) Produce a report that describes your conclusions. Use LaTex or similar. (6) The reference solution is 350 lines of Java, 40 lines of R, and 150 line of Make.

A4 Regression
Time: 1 week
Prerequisites: Map Reduce I, Data analysis with R
Description:
The price of a ticket depends, in part, on the fuel consumed, figuring out which airline is cheapest requires a little bit of work. Write a MapReduce job that ranks carriers and plots the evolution of prices of the least expensive carrier over time.
Fine Print:
(0) Group assignment, two students. (1) Take as input "-time=N" where N is a natural number representing scheduled flight minutes.  (2) For each year and each carrier, estimate the intercept and the slope of a simple linear regression using the scheduled flight time to explain average ticket prices. For a given year, compare carriers at N by computing intercept+slope*N. The least expensive carrier is the carrier with lowest price at N for the most years. (3)  Plot, for each week of the entire dataset, the median price of the least expensive carrier.  (4) The reference solution is 300 LOC of Java with two MR jobs pipelined. (5) Use the full airline dataset form s3://mrclassvitek/data -- it contains 337 files! (6) Produce a report that discusses your results and includes graphs for N=1 and N=200. (7) The reference solution has 300 lines of Java.

A5 Paths
Time: 1 week
Prerequisites: Map Reduce II, Data analysis with R
Description:
Compute missed connections for all two-hop paths.
Fine Print:
(0) Group assignment, two students. (1) A connection is any pair of flight F and G of the same carrier such as F.Destination = G.Origin and the scheduled departure of G is  <= 6 hours and >= 30 minutes after the scheduled arrival of F. (2) A connection is missed when the actual arrival of F < 30 minutes before the actual departure of G. (3) Optimize your code for performance. (4) Output the number of connections and missed connections per airline, per year. (5) The reference solution outputs "UA, 2013, 2826, 129" when processing the following two files. (6) The reference solution is 239 LOC Java and 10 LOC of R.  The reference solutions takes 5 minutes to run on the full data set (337 files) with a cluster of 10 large machines. (7) Your submission should include code and Makefiles. No data should be included. A report should describe your implementation and detail the timing of your results for at least the two year data set, and, if you dare, the full data set. Include results file for any runs on AWS. The report should be in PDF.

A6 Prediction
Time: 1 week
Prerequisites: Map Reduce II, Data analysis with R
Description:
Build a model to predict flight delays.
Fine print:
(0) Group assignment, two students. (1) Your program takes as input 36 historical files. Each file is a month of data. You can use these to build a model. (2) You program also take a single test file. This represents all the future flights we want to predict. (3) Output a file containing predictions in the format <FL_NUM>_<FL_DATE>_<CRS_DEP_TIME>, logical. The first column uniquely identifies a flight and the second is TRUE if the flight will be late. (4) Report execution time and the confusion matrix for the provided data. (5) The choice of predictive model is open; you will be graded on the accuracy of your method as well as execution time. One possible choice is to use the Random Forest algorithm. R and Java implementations exist. (6) Input data is to be found in bucked s3://mrclassvitek, in folders a6history and a6test.  The folder a6validate contains a file that has the correct answers for most flights, use it to compute the confusion matrix. (7) As a measure of accuracy, use the sum of the percentage of on-time flights misclassified as delayed and the percentage of delayed flights misclassified as on-time. (8) Some hints for using random forests: (a) split the data and build models for subsets of the entire data set. (b) Recode the data so that the type of each column has at most 50 different values. In R, they should be factors. (c) Delete columns that are not usable for predictions. (d) Synthesize features that you think make sense. For example you could create a column labelled "Holidays" and it would be true when a flight is close to Christmas, New Year, and Thanksgiving. (8) A flight is delayed is ARR_DELAY > 0.

A7 Routing
Time: 1 week
Prerequisites: Map Reduce II, Data analysis with R
Description:
Given an origin, a destination and a date, propose two-hops routes that minimize the chance of missed connections.
Fine print:
(0) Group assignment, four students. (1) Your program takes 36 history files to build a model, one single test file that contains all scheduled flights for the next year, to create itineraries, and one request file in the following format  year, month, day, origin, destination, ignore. For each request, your program should propose an itinerary, written flight_num, flight_num, duration.  (3) The output of the program is scored as follows: sum the durations in hours. Add 100 hours for each missed connection. (4) Connections must have at least 30 minutes and no more than one hour on the same carrier. (5) The data is in the bucket s3://mrclassvitek, in folders a7history, a7test, a7request and a7validate.  The last directory contains a file which lists missed connections, use it for scoring. (6) The PDF report file should include details about the implementation as well as a study of the performance and accuracy of the solution. A detailed breakdown of what each team member worked should be added. Grading will include the quality of the report. All projects will be code walked.

A8 Regression in Spark
Time: 1 week
Prerequisites: A4, Spark: Basics, Data analysis with R
Description:
Reimplement A4 in Scala using Spark.
Fine print:
(0) Group assignment, four students. (1) Your report should include a detailed comparison of the two solutions in terms of performance and software engineering.

X9 Paths in Spark
Time: 1 week
Prerequisites: A8, A5, Spark: Accumulators and broadcast variables
Description:
Use the ranking from A8 to create a map of airline prices. Using that map find whether there is a correlation between airline prices and missed connections for two-hop paths.
Fine print:

X10 Spark III (TBA)
Time: 1 week
Prerequisites: A4, Spark: Relational databases
Description:
Fine print:

X11 Spark IV (TBA)
Time: 1 week
Prerequisites: A4, Spark: Scaling
Description:
Fine print:

X12 Spark V (TBA)
Time: 1 week
Prerequisites: A4, Spark: Streaming
Description:
Fine print:

